# AI Engine-ML Graph: Four-Layer Neural Network with Roll-Concat

This directory implements a four-layer neural network graph featuring a roll-concat operation and shared buffer tiling for efficient memory access across a large cascaded matrix multiply.

## Architecture

### Pipeline
1. **`roll_concat`** – Repeats input 128-element vector 6 times to create 768 elements
2. **`dense0`** (768×128, cascade length=12) – Large matrix-vector multiply with shared buffer input
3. **`bias_add`** → **`leaky_relu`** → **`window_split_128_to_64x2`**
4. **`dense1`** (128×128, cascade length=2) – Second dense layer
5. **`bias_add`** → **`leaky_relu`** → **`window_split_128_to_64x2`**
6. **`dense2`** (128×128, cascade length=2) – Third dense layer
7. **`bias_add`** → **`leaky_relu`** → **`window_split_128_to_64x2`**
8. **`dense3`** (128×128, cascade length=2) – Fourth dense layer
9. **`bias_add`** → **`leaky_relu`** – Final output

### Key Features
- **Shared Activation Buffer**: 768-element roll-concat buffer tiled across 12 cascade kernels for dense0 inputs
- **Shared Weight/Bias Streams**: Concatenated dense weights and biases arrive over dedicated PLIOs and are staged in shared
  buffers with 12,288-float-max tiles for every cascade leg
- **Roll-Concat**: Efficiently replicates 128→768 elements for large matrix input
- **4 Dense Layers**: Progressive transformation from 768 inputs to 128 outputs

### Layer Configurations
- **Layer 0**: 768×128 dense layer with 12-way cascade (TP_CASC_LEN_LAYER3=12)
- **Layers 1-3**: 128×128 dense layers with 2-way cascade (TP_CASC_LEN_LAYER2=2)
- **Activation**: Leaky ReLU with slope 0.1
- **Tiling**: `ROLL_CONCAT_TILE_SPAN = 768 / 12 = 64` elements per cascade tile

## Directory Layout

```
├── graph.cpp                       # Instantiates NeuralNetworkGraph
├── graph.h                         # Graph definition with shared buffers for activations, weights, and biases
├── leaky_relu.cpp/.h               # Leaky ReLU activation kernel
├── bias_add.cpp/.h                 # Bias addition kernel
├── window_split_128_to_64x2.cpp/.h # Window splitter for cascade inputs
├── roll_concat.cpp/.h              # Roll-concat kernel (128→768)
├── window_split_768_to_*.h         # Additional window split utilities (unused)
├── aie.cfg                         # AIE compiler configuration
└── Makefile                        # Build targets
```

## Build & Simulation

### Compile AI Engine Graph
```bash
cd aieml7
make graph TARGET=hw       # or TARGET=hw_emu
```
Produces `Work/libadf.a` containing the compiled graph.

### Run AI Engine Simulation
```bash
make sim
```

## Data Flow

### Input/Output PLIO
- **Input**: `layer0_in` reads from `../data/tmp_inp768.txt` (128 floats)
- **Weights**: `weights_in` ingests the concatenated stream `../data/solver_0_dense_weights_stream.txt`
- **Biases**: `biases_in` ingests the concatenated stream `../data/solver_0_dense_biases_stream.txt`
- **Output**: `layer_out` writes to `../data/subsolver_0_dense_3_output_aie.txt` (128 floats)

### Shared Weight & Bias Staging
- `graph.cpp` concatenates the per-cascade weight parts (`12 × 8,192` floats for dense0 and `3 × (2 × 8,192)` floats for dense1–3)
  into a single 147,456-float stream before `g.init()`. Bias files (4 × 128 floats) are concatenated similarly.
- `weights_in` writes directly into a shared buffer with 18 uniform tiles (each 8,192 floats ≤ the 12,288-float cap).
  Dense cascades index their tile via explicit offsets so every leg receives its aligned slice.
- `biases_in` stages four 128-float tiles inside a shared buffer. Each bias_add kernel consumes its tile through a
  pointer view, matching the leaky-ReLU fan-out while keeping on-chip storage minimal (≈2 kB for biases).

### Processing Pipeline
```
input(128) → roll_concat(128→768) → shared_buffer[768] →
dense0(768×128, casc=12) → bias → leaky_relu → split →
dense1(128×128, casc=2) → bias → leaky_relu → split →
dense2(128×128, casc=2) → bias → leaky_relu → split →
dense3(128×128, casc=2) → bias → leaky_relu → output(128)
```

## Shared Buffer Tiling

The roll-concat output uses a shared buffer with tiled access:
- **Buffer Size**: 768 floats
- **Number of Consumers**: 12 (cascade kernels in dense0)
- **Tile Size**: 64 floats per consumer
- **Write Access**: Single writer (roll_concat kernel) writes entire 768-element buffer
- **Read Access**: Each of 12 cascade kernels reads its own 64-element tile with stride offset

## Notes
- Test data is generated by `../data/generate_test_data.py`
- This architecture demonstrates efficient shared buffer usage for large cascaded operations
- Kernel placement can be manually specified via `location<kernel>` directives in graph.h
- This graph serves as the "solver" component tested independently before integration into aieml9
