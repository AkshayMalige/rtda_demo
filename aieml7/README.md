# AI Engine-ML Graph: Four-Layer Neural Network with Roll-Concat

This directory implements a four-layer neural network graph featuring a roll-concat operation and shared buffer tiling for efficient memory access across a large cascaded matrix multiply.

## Architecture

### Pipeline
1. **`roll_concat`** – Repeats input 128-element vector 6 times to create 768 elements
2. **`dense0`** (768×128, cascade length=12) – Large matrix-vector multiply with shared buffer input
3. **`bias_add`** → **`leaky_relu`** → **`window_split_128_to_64x2`**
4. **`dense1`** (128×128, cascade length=2) – Second dense layer
5. **`bias_add`** → **`leaky_relu`** → **`window_split_128_to_64x2`**
6. **`dense2`** (128×128, cascade length=2) – Third dense layer
7. **`bias_add`** → **`leaky_relu`** → **`window_split_128_to_64x2`**
8. **`dense3`** (128×128, cascade length=2) – Fourth dense layer
9. **`bias_add`** → **`leaky_relu`** – Final output

### Key Features
- **Shared Buffer**: 768-element buffer tiled across 12 cascade kernels for dense0
- **Roll-Concat**: Efficiently replicates 128→768 elements for large matrix input
- **4 Dense Layers**: Progressive transformation from 768 inputs to 128 outputs
- All weights loaded via RTP (runtime parameters)

### Layer Configurations
- **Layer 0**: 768×128 dense layer with 12-way cascade (TP_CASC_LEN_LAYER3=12)
- **Layers 1-3**: 128×128 dense layers with 2-way cascade (TP_CASC_LEN_LAYER2=2)
- **Activation**: Leaky ReLU with slope 0.1
- **Tiling**: `ROLL_CONCAT_TILE_SPAN = 768 / 12 = 64` elements per cascade tile

## Directory Layout

```
├── graph.cpp                       # Instantiates NeuralNetworkGraph
├── graph.h                         # Graph definition with shared buffer and RTP connections
├── leaky_relu.cpp/.h               # Leaky ReLU activation kernel
├── bias_add.cpp/.h                 # Bias addition kernel
├── window_split_128_to_64x2.cpp/.h # Window splitter for cascade inputs
├── roll_concat.cpp/.h              # Roll-concat kernel (128→768)
├── window_split_768_to_*.h         # Additional window split utilities (unused)
├── aie.cfg                         # AIE compiler configuration
└── Makefile                        # Build targets
```

## Build & Simulation

### Compile AI Engine Graph
```bash
cd aieml7
make graph TARGET=hw       # or TARGET=hw_emu
```
Produces `Work/libadf.a` containing the compiled graph.

### Run AI Engine Simulation
```bash
make sim
```

## Data Flow

### Input/Output PLIO
- **Input**: `layer0_in` reads from `../data/tmp_inp768.txt` (128 floats)
- **Output**: `layer_out` writes to `../data/subsolver_0_dense_3_output_aie.txt` (128 floats)

### Runtime Parameters (RTP)
Weights provided via RTP connections:
- `matrixA_dense0_rtp[12]`: Twelve weight matrices for 12-way cascaded dense0
- `bias_dense0_rtp`: 128-element bias for dense0
- `matrixA_dense1_rtp[2]`: Two weight matrices for 2-way cascaded dense1
- `bias_dense1_rtp`: 128-element bias for dense1
- `matrixA_dense2_rtp[2]`: Two weight matrices for 2-way cascaded dense2
- `bias_dense2_rtp`: 128-element bias for dense2
- `matrixA_dense3_rtp[2]`: Two weight matrices for 2-way cascaded dense3
- `bias_dense3_rtp`: 128-element bias for dense3

### Processing Pipeline
```
input(128) → roll_concat(128→768) → shared_buffer[768] →
dense0(768×128, casc=12) → bias → leaky_relu → split →
dense1(128×128, casc=2) → bias → leaky_relu → split →
dense2(128×128, casc=2) → bias → leaky_relu → split →
dense3(128×128, casc=2) → bias → leaky_relu → output(128)
```

## Shared Buffer Tiling

The roll-concat output uses a shared buffer with tiled access:
- **Buffer Size**: 768 floats
- **Number of Consumers**: 12 (cascade kernels in dense0)
- **Tile Size**: 64 floats per consumer
- **Write Access**: Single writer (roll_concat kernel) writes entire 768-element buffer
- **Read Access**: Each of 12 cascade kernels reads its own 64-element tile with stride offset

## Notes
- Test data is generated by `../data/generate_test_data.py`
- This architecture demonstrates efficient shared buffer usage for large cascaded operations
- Kernel placement can be manually specified via `location<kernel>` directives in graph.h
- This graph serves as the "solver" component tested independently before integration into aieml9
