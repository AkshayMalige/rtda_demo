{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b60d555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import onnxruntime\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from rtal.datasets.dataset import ROMDataset\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a245bc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from /home/synthara/VersalPrjs/LDRD/rtda_demo/model/RealTimeAlignment/onnx_no-residual/data/rom_det-3_part-200_cont-and-rounded_excerpt\n",
      "Using config /home/synthara/VersalPrjs/LDRD/rtda_demo/model/RealTimeAlignment/onnx_no-residual/checkpoints/config.yaml\n",
      "Using ONNX model /home/synthara/VersalPrjs/LDRD/rtda_demo/model/RealTimeAlignment/onnx_no-residual/onnx_files_narrow_but_deep_untrained/mlp_half.onnx\n",
      "Loaded configuration: num_particles=50, in_features=6\n"
     ]
    }
   ],
   "source": [
    "# Paths and run-time configuration\n",
    "from pathlib import Path\n",
    "\n",
    "NOTEBOOK_DIR = Path(__file__).resolve().parent if '__file__' in globals() else Path.cwd()\n",
    "\n",
    "ROOT_DIR = None\n",
    "for candidate in [NOTEBOOK_DIR, *NOTEBOOK_DIR.parents]:\n",
    "    if (candidate / 'checkpoints').exists() and (candidate / 'onnx_files_narrow_but_deep_untrained').exists():\n",
    "        ROOT_DIR = candidate\n",
    "        break\n",
    "\n",
    "if ROOT_DIR is None:\n",
    "    raise FileNotFoundError(\n",
    "        'Could not locate project root. Please set ROOT_DIR manually to the directory that contains the checkpoints folder.'\n",
    "    )\n",
    "\n",
    "DATA_ROOT = ROOT_DIR / 'data/rom_det-3_part-200_cont-and-rounded_excerpt/'\n",
    "CONFIG_PATH = ROOT_DIR / 'checkpoints/config.yaml'\n",
    "ONNX_MODEL_PATH = ROOT_DIR / 'onnx_files_narrow_but_deep_untrained/mlp_half.onnx'\n",
    "NUM_SAMPLES = 10  # number of inputs to benchmark\n",
    "THREAD_COUNTS = [1, 2, 3, 4, 5, 6, 7, 8]  # CPU thread counts to test\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "print(f'Using data from {DATA_ROOT}')\n",
    "print(f'Using config {CONFIG_PATH}')\n",
    "print(f'Using ONNX model {ONNX_MODEL_PATH}')\n",
    "\n",
    "with open(CONFIG_PATH, 'r', encoding='utf-8') as handle:\n",
    "    config = yaml.safe_load(handle)\n",
    "\n",
    "num_particles = config['data']['num_particles']\n",
    "model_in_features = config['model']['in_features']\n",
    "print(f\"Loaded configuration: num_particles={num_particles}, in_features={model_in_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6d48a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 10 samples (requested 10) with shape (1, 50, 6) for benchmarking.\n"
     ]
    }
   ],
   "source": [
    "# Collect inputs for benchmarking\n",
    "if not DATA_ROOT.exists():\n",
    "    raise FileNotFoundError(f'Dataset directory {DATA_ROOT} does not exist. Please check ROOT_DIR/data configuration.')\n",
    "\n",
    "dataset = ROMDataset(str(DATA_ROOT), split='train', num_particles=num_particles)\n",
    "dataset_size = len(dataset)\n",
    "if dataset_size == 0:\n",
    "    raise RuntimeError(f'Found zero samples under {DATA_ROOT} (split=\"train\").')\n",
    "\n",
    "samples_to_collect = min(NUM_SAMPLES, dataset_size)\n",
    "if samples_to_collect < NUM_SAMPLES:\n",
    "    print(f'Only {samples_to_collect} samples available; will benchmark on all of them instead of the requested {NUM_SAMPLES}.')\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "inputs = []\n",
    "for event_idx, event in enumerate(dataloader):\n",
    "    readout = event['readout_curr_cont']\n",
    "    readout = torch.transpose(readout, 1, 2).flatten(-2, -1)\n",
    "    sample = readout.detach().to(torch.float16).cpu().numpy()\n",
    "    inputs.append(sample)\n",
    "    if len(inputs) >= samples_to_collect:\n",
    "        break\n",
    "\n",
    "if not inputs:\n",
    "    raise RuntimeError(f'Failed to collect samples from {DATA_ROOT} (processed 0 batches).')\n",
    "\n",
    "print(f'Collected {len(inputs)} samples (requested {NUM_SAMPLES}) with shape {inputs[0].shape} for benchmarking.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9343f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_cpu(inputs, num_threads, onnx_path):\n",
    "    '''Run the ONNX model on CPU and capture timing breakdowns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    inputs : list[np.ndarray]\n",
    "        List of input batches shaped like (1, num_particles, in_features).\n",
    "    num_threads : int\n",
    "        Number of CPU threads to allow ONNX Runtime to use.\n",
    "    onnx_path : Path\n",
    "        Path to the ONNX model.\n",
    "    '''\n",
    "    session_options = onnxruntime.SessionOptions()\n",
    "    session_options.intra_op_num_threads = num_threads\n",
    "    session_options.inter_op_num_threads = 1\n",
    "    session_options.execution_mode = onnxruntime.ExecutionMode.ORT_SEQUENTIAL\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    session = onnxruntime.InferenceSession(str(onnx_path), sess_options=session_options, providers=['CPUExecutionProvider'])\n",
    "    load_ms = (time.perf_counter() - t0) * 1e3\n",
    "\n",
    "    input_transfer_ms = 0.0\n",
    "    output_read_ms = 0.0\n",
    "    graph_exec_ms = 0.0\n",
    "\n",
    "    input_name = session.get_inputs()[0].name\n",
    "\n",
    "    for sample in inputs:\n",
    "        t_in_start = time.perf_counter()\n",
    "        ort_inputs = {input_name: sample}\n",
    "        t_in_end = time.perf_counter()\n",
    "        outputs = session.run(None, ort_inputs)\n",
    "        t_run_end = time.perf_counter()\n",
    "        _ = outputs[0]\n",
    "        t_out_end = time.perf_counter()\n",
    "\n",
    "        input_transfer_ms += (t_in_end - t_in_start) * 1e3\n",
    "        graph_exec_ms += (t_run_end - t_in_end) * 1e3\n",
    "        output_read_ms += (t_out_end - t_run_end) * 1e3\n",
    "\n",
    "    samples = len(inputs)\n",
    "    graph_exec_per_input_ms = graph_exec_ms / samples\n",
    "    host_total_overall_ms = load_ms + input_transfer_ms + output_read_ms + graph_exec_ms\n",
    "    host_total_per_input_ms = host_total_overall_ms / samples\n",
    "\n",
    "    return {\n",
    "        'threads': num_threads,\n",
    "        'weights/bias transfer (ms)': load_ms,\n",
    "        'no. of inputs': samples,\n",
    "        'input transfer (ms)': input_transfer_ms,\n",
    "        'output read (ms)': output_read_ms,\n",
    "        'graph exec (total ms)': graph_exec_ms,\n",
    "        'graph exec per input (ms)': graph_exec_per_input_ms,\n",
    "        'host total per input (ms)': host_total_per_input_ms,\n",
    "        'host total (overall ms)': host_total_overall_ms,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9949d717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weights/bias transfer (ms)</th>\n",
       "      <th>no. of inputs</th>\n",
       "      <th>input transfer (ms)</th>\n",
       "      <th>output read (ms)</th>\n",
       "      <th>graph exec (total ms)</th>\n",
       "      <th>graph exec per input (ms)</th>\n",
       "      <th>host total per input (ms)</th>\n",
       "      <th>host total (overall ms)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threads</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.491118</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.008936</td>\n",
       "      <td>11.722563</td>\n",
       "      <td>1.172256</td>\n",
       "      <td>1.822589</td>\n",
       "      <td>18.225893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.169051</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002765</td>\n",
       "      <td>0.008943</td>\n",
       "      <td>13.673847</td>\n",
       "      <td>1.367385</td>\n",
       "      <td>1.885461</td>\n",
       "      <td>18.854606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.684597</td>\n",
       "      <td>10</td>\n",
       "      <td>0.003606</td>\n",
       "      <td>0.009635</td>\n",
       "      <td>13.342780</td>\n",
       "      <td>1.334278</td>\n",
       "      <td>1.904062</td>\n",
       "      <td>19.040618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.477669</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.008062</td>\n",
       "      <td>10.682279</td>\n",
       "      <td>1.068228</td>\n",
       "      <td>1.417025</td>\n",
       "      <td>14.170253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.521425</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002284</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>10.610810</td>\n",
       "      <td>1.061081</td>\n",
       "      <td>1.414218</td>\n",
       "      <td>14.142183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.573643</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.009264</td>\n",
       "      <td>11.925808</td>\n",
       "      <td>1.192581</td>\n",
       "      <td>1.551141</td>\n",
       "      <td>15.511408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.701074</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.008952</td>\n",
       "      <td>11.525888</td>\n",
       "      <td>1.152589</td>\n",
       "      <td>1.523854</td>\n",
       "      <td>15.238539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.410831</td>\n",
       "      <td>10</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>0.007693</td>\n",
       "      <td>13.262958</td>\n",
       "      <td>1.326296</td>\n",
       "      <td>1.768421</td>\n",
       "      <td>17.684215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         weights/bias transfer (ms)  no. of inputs  input transfer (ms)  \\\n",
       "threads                                                                   \n",
       "1                          6.491118             10             0.003276   \n",
       "2                          5.169051             10             0.002765   \n",
       "3                          5.684597             10             0.003606   \n",
       "4                          3.477669             10             0.002243   \n",
       "5                          3.521425             10             0.002284   \n",
       "6                          3.573643             10             0.002693   \n",
       "7                          3.701074             10             0.002625   \n",
       "8                          4.410831             10             0.002733   \n",
       "\n",
       "         output read (ms)  graph exec (total ms)  graph exec per input (ms)  \\\n",
       "threads                                                                       \n",
       "1                0.008936              11.722563                   1.172256   \n",
       "2                0.008943              13.673847                   1.367385   \n",
       "3                0.009635              13.342780                   1.334278   \n",
       "4                0.008062              10.682279                   1.068228   \n",
       "5                0.007663              10.610810                   1.061081   \n",
       "6                0.009264              11.925808                   1.192581   \n",
       "7                0.008952              11.525888                   1.152589   \n",
       "8                0.007693              13.262958                   1.326296   \n",
       "\n",
       "         host total per input (ms)  host total (overall ms)  \n",
       "threads                                                      \n",
       "1                         1.822589                18.225893  \n",
       "2                         1.885461                18.854606  \n",
       "3                         1.904062                19.040618  \n",
       "4                         1.417025                14.170253  \n",
       "5                         1.414218                14.142183  \n",
       "6                         1.551141                15.511408  \n",
       "7                         1.523854                15.238539  \n",
       "8                         1.768421                17.684215  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [benchmark_cpu(inputs, num_threads=n, onnx_path=ONNX_MODEL_PATH) for n in THREAD_COUNTS]\n",
    "df_results = pd.DataFrame(results).set_index('threads')\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba2329c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f3020b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
