# ğŸ§  AI Engine-ML Neural Network Pipeline: Dense1 â†’ LeakyReLU â†’ Dense2 â†’ LeakyReLU

This project demonstrates custom low-latency neural network pipelines implemented on the AMD Versalâ„¢ VEK280 platform using the AI Engine-ML (AIEâ€‘ML) and Vitis tools. The core model family uses dense layers with leaky ReLU activations, targeting powerâ€‘efficient acceleration of small MLP inference tasks. It supports runtime configurability of dimensions and data types (`int8`, `int16`, `float16`, `float32`), with automated test data generation and full simulation support.

The design partitions work across three components of the Versal architecture:

- **AI Engineâ€‘ML graphs** â€“ execute dense layers. The project contains several
  variants:
  - `aieml/` â€“ embedding graph (`dense1 â†’ dense2`).
  - `aieml2/` â€“ subâ€‘solver graph with four consecutive dense layers.
  - `aieml3/` â€“ output head projecting to 27 classes (padded to 32).
  - `aieml10/` â€“ extended endâ€‘toâ€‘end pipeline: embed (8â†’128) + leaky ReLU, embed (128â†’128) + leaky ReLU, a 256â€‘toâ€‘128 solver chain replicated across branches, and a final (128â†’32 padded) projection head. See â€œAIEML10 Detailsâ€ below.
- **Convenience build targets** â€“ choose a graph at the top level by setting the
  `GRAPH` variable or invoking one of the shortcut targets. For example:

  ```bash
  make aieml2 TARGET=hw_emu
  ```

  Valid graphs are `aieml`, `aieml2`, and `aieml3`.

  Note: `aieml10` is currently a standalone AIE project with its own Makefile and is not wired into the topâ€‘level `GRAPH` flow. Build and simulate it from `aieml10/`.
- **Programmable Logic (PL)** â€“ supplies dataâ€‘mover kernels and two leaky ReLU units.
- **Host application** â€“ runs on the processing system and orchestrates data movement and graph execution through XRT.

All build instructions are split into component READMEs:

- [AI Engineâ€‘ML graphs](aieml/README.md) (see also [`aieml2`](aieml2/README.md) and [`aieml3`](aieml3/README.md))
- [Programmable Logic](pl/README.md)
- [Host Application](host/README.md)

For `aieml10`, use the section below until itâ€™s integrated into the topâ€‘level build.

Recent refactoring introduced a shared `common/data_paths.h` header and a `DATA_DIR`
environment variable so the host, PL tests, and AIE graphs can locate generated text
files consistently across components.

---

## ğŸ“¦ Python Environment Setup

To set up the Python environment for generating test inputs, weights, and golden reference outputs:

```bash
conda env create -f hls_env.yml
conda activate hls_env
```

### Activate hardware toolchain paths:

```bash
source set_envs.sh
```

---

## ğŸ” Workflow

1. **Data generation**
   ```bash
   python data/generate_test_data.py --input-dim 6 --hidden-dim 128 --output-dim 128 --dtype float32 --seed 123
   ```
2. **Graph compilation**
   ```bash
   make -C aieml graph
   ```
3. **Kernel build (PL)**
   ```bash
   make -C pl kernels
   ```
4. **Host build**
   ```bash
   make -C host
   ```
5. **System linking and packaging**
   ```bash
   make package
   ```

---

## ğŸ§ª Generate Dummy Test Data & Weights

This command will generate:

- `input_data.txt` for the first dense layer
- `weights_dense1a.txt`, `weights_dense1b.txt`
- `weights_dense2a.txt`, `weights_dense2b.txt`
- `reference_output_data.txt` for validation

```bash
python data/generate_test_data.py --input-dim 6 --hidden-dim 128 --output-dim 128 --dtype float32 --seed 123
```

> âš™ï¸ All data is dumped into the project-parent `../data/` directory and formatted for `plio` input streams.

---

## âš™ï¸ Build the AIE Graph: `dense1 â†’ leaky_relu â†’ dense2`

Move into the AIE source directory and compile the graph:

```bash
cd aieml
make graph
```

This generates `Work/libadf.a` for linking with the rest of the system.

---

## â–¶ï¸ Simulate the AIE Graph

Run cycle-approximate simulation with profiling and memory tracking enabled:

```bash
cd aieml
make sim
```

Simulation results can be inspected in Vitis Analyzer:

```bash
vitis_analyzer Work/aiesimulator_output/default.aierun_summary
```

> ğŸ’¡ Use this to inspect PLIO transactions, kernel traces, and memory usage to verify correctness and debug stalls.

---

## AIEML10 Details

- Graph path: `aieml10/`
- Output file: `../data/aieml10_output_aie.txt` (default `DATA_DIR`)
- AIE target: `hw` by default (set `TARGET=x86sim` for x86 AIE compile)

Architecture
- Embed stage: `dense 8Ã—128` â†’ bias add â†’ `leaky_relu` â†’ `dense 128Ã—128` (2â€‘way cascade) â†’ bias add â†’ `leaky_relu`.
- Solver stage: rollâ€‘concat expands to 256; a `256Ã—128` dense (4â€‘way cascaded inputs) feeds three successive `128Ã—128` dense layers, each separated by bias add, `leaky_relu`, and a 128â†’64Ã—2 split feeding dual inputs. This chain is replicated into additional branches to increase compute depth (see `aieml10/graph.h`).
- Output head: `128â†’32` (padded) projection using a matrix reload RTP.

Build and simulate
- Activate toolchain: `source set_envs.sh` and Conda as in Setup below.
- Optional dataset override: `export DATA_DIR=$PWD/data_casc8`
- Compile graph: `make -C aieml10 graph TARGET=hw`
- Simulate: `make -C aieml10 sim`

Data files (placeholders)
- Input: `embed_input.txt`
- Embed weights (PLIOâ€‘fed):
  - `embed_dense_0_weights.txt`
  - `embed_dense_1_weights_part0.txt`, `embed_dense_1_weights_part1.txt`
- Embed bias (RTP):
  - `embed_dense_0_bias.txt`
  - `embed_dense_1_bias.txt`
- Solver weights (PLIOâ€‘fed):
  - `solver_0_dense_0_weights_part0.txt` â€¦ `part3.txt` (4 parts)
  - `solver_0_dense_1_weights_part0.txt`, `part1.txt` (2 parts)
  - `solver_0_dense_2_weights_part0.txt`, `part1.txt` (2 parts)
  - `solver_0_dense_3_weights_part0.txt`, `part1.txt` (2 parts)
- Solver bias (RTP, applied to all branches):
  - `solver_0_dense_0_bias.txt`
  - `solver_0_dense_1_bias.txt`
  - `solver_0_dense_2_bias.txt`
  - `solver_0_dense_3_bias.txt`
- Output head weights (RTP):
  - `output_dense_0_weights.txt`

Notes
- The `.txt` weights and bias files listed here are placeholders used for simulation bringâ€‘up. Replace them with correct artifacts when available; file names must match those in `common/data_paths.h`.
- `DATA_DIR` defaults to `../data` for all components; override with `export DATA_DIR=/path/to/your/data` to point at alternate datasets.
- Simulation loads biases and the final output matrix via RTP at runtime (`aieml10/graph.cpp`), while most intermediate weights are streamed via PLIO from `DATA_DIR`.

---

## ğŸ“ Directory Structure Overview

Your project is organized as follows:

```bash
â”œâ”€â”€ aieml/
â”‚   â”œâ”€â”€ Makefile
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ graph.cpp
â”‚   â””â”€â”€ graph.h
â”œâ”€â”€ aieml10/                 # Standalone AIE graph (see section above)
â”‚   â”œâ”€â”€ Makefile
â”‚   â”œâ”€â”€ graph.cpp
â”‚   â”œâ”€â”€ graph.h
â”‚   â”œâ”€â”€ graph_layout.hpp
â”‚   â”œâ”€â”€ nn_defs10.h
â”‚   â””â”€â”€ kernels: leaky_relu, bias_add, split, roll_concat
â”œâ”€â”€ ../data/                  # Generated input, weights, and reference output
â”œâ”€â”€ pl/                       # Programmable logic (HLS) kernels
â”‚   â”œâ”€â”€ Makefile
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ host/                     # Host application sources
â”‚   â”œâ”€â”€ Makefile
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ common/                   # Shared headers and configuration
â”‚   â””â”€â”€ nn_defs.h            # Neural network constants
â”œâ”€â”€ model/                    # Python models and utilities
â”œâ”€â”€ hls_env.yml               # Conda environment definition
â”œâ”€â”€ pack.cfg                  # Packaging configuration
â”œâ”€â”€ set_envs.sh               # Vitis and XRT environment setup
â”œâ”€â”€ system_project.yaml       # System project description
â””â”€â”€ Makefile                  # Top-level build orchestrator
```

---

## ğŸš§ Notes & WIP

- This design assumes full window-based streaming between kernels using PLIO.
- `dense2` expects the output from `leaky_relu` in full windows â€” ensure the dummy data generator creates enough input samples.
- Current focus is on validating functional correctness before host-integration or hardware execution.
