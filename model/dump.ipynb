{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === CONFIG ===\n",
    "ONNX_DIR      = Path(\"submodule_onnx\")\n",
    "EMBED_ONNX    = ONNX_DIR / \"submodule_embed.onnx\"\n",
    "SOLVER_GLOB   = \"submodule_solvers-*.onnx\"\n",
    "OUTPUT_ONNX   = ONNX_DIR / \"submodule_output.onnx\"\n",
    "\n",
    "OUTPUT_ROOT   = Path(\"onnx_txt\")\n",
    "TMP_MODEL_DIR = Path(\"tmp_instrumented_models\")\n",
    "TXT_FLOAT_FMT = \"%.8g\"\n",
    "\n",
    "# ROMDataset\n",
    "DATA_ROOT   = \"data/rom_det-3_part-200_cont-and-rounded_excerpt/\"\n",
    "SPLIT       = \"train\"\n",
    "BATCH_SIZE  = 1\n",
    "FEATURE_KEY = \"readout_curr_cont\"\n",
    "DEVICE = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import onnx, onnxruntime as ort\n",
    "from onnx import numpy_helper, helper, shape_inference\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from rtal.datasets.dataset import ROMDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ensure_dir(p: Path): p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def sanitize(name: str) -> str:\n",
    "    for b in ['/', '\\\\', ':', '*', '?', '\"', '<', '>', '|', ' ']:\n",
    "        name = name.replace(b, '_')\n",
    "    return name\n",
    "\n",
    "def dump_txt(path: Path, arr: np.ndarray, fmt: str = \"%.8g\"):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    flat = np.asarray(arr).ravel()\n",
    "    with open(path, \"w\") as f:\n",
    "        for v in flat:\n",
    "            f.write((fmt % float(v)) + \"\\n\")\n",
    "\n",
    "def ort_session(path: Path):\n",
    "    so = ort.SessionOptions()\n",
    "    so.graph_optimization_level = ort.GraphOptimizationLevel.ORT_DISABLE_ALL\n",
    "    return ort.InferenceSession(str(path), so, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "def concrete_dims(shape: Tuple) -> Tuple:\n",
    "    return tuple(int(s) if isinstance(s,(int,np.integer)) else None for s in shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Bias-aware graph introspection ----\n",
    "def build_maps(model):\n",
    "    g = model.graph\n",
    "    init_map = {init.name: numpy_helper.to_array(init) for init in g.initializer}\n",
    "    const_map = {}\n",
    "    producers = {}\n",
    "    for n in g.node:\n",
    "        for o in n.output:\n",
    "            producers[o] = n\n",
    "        if n.op_type == \"Constant\":\n",
    "            for a in n.attribute:\n",
    "                if a.name == \"value\":\n",
    "                    const_map[n.output[0]] = numpy_helper.to_array(a.t)\n",
    "    consumers = {}\n",
    "    for n in g.node:\n",
    "        for i in n.input:\n",
    "            consumers.setdefault(i, []).append(n)\n",
    "    return init_map, const_map, consumers, producers\n",
    "\n",
    "def resolve_bias_tensor(name: Optional[str], init_map, const_map, producers):\n",
    "    if not name:\n",
    "        return None\n",
    "    if name in init_map:\n",
    "        return init_map[name]\n",
    "    if name in const_map:\n",
    "        return const_map[name]\n",
    "    prod = producers.get(name)\n",
    "    if prod is not None and prod.op_type == \"Constant\":\n",
    "        for a in prod.attribute:\n",
    "            if a.name == \"value\":\n",
    "                return numpy_helper.to_array(a.t)\n",
    "    return None\n",
    "\n",
    "def list_dense_with_bias_and_outputs(model) -> List[Dict]:\n",
    "    \"\"\"Identify dense-like operations and their output tensors, weights, and bias.\n",
    "       - Gemm: W=input[1], B=input[2] (resolve Constant as well), out = node.output[0]\n",
    "       - MatMul(+Add): W=MatMul input[1], B=Add's non-MM input (resolve Constant), out = Add output (or MatMul output if no Add)\n",
    "    \"\"\"\n",
    "    dense = []\n",
    "    g = model.graph\n",
    "    init_map, const_map, consumers, producers = build_maps(model)\n",
    "    idx = 0\n",
    "    for n in g.node:\n",
    "        if n.op_type == \"Gemm\":\n",
    "            Wname = n.input[1] if len(n.input)>1 else None\n",
    "            Bname = n.input[2] if len(n.input)>2 else None\n",
    "            W = init_map.get(Wname)\n",
    "            B = resolve_bias_tensor(Bname, init_map, const_map, producers)\n",
    "            dense.append({\"kind\":\"Gemm\",\"index\":idx,\"out\":n.output[0],\"W\":W,\"B\":B})\n",
    "            idx += 1\n",
    "        elif n.op_type == \"MatMul\":\n",
    "            mm_out = n.output[0]\n",
    "            add_node = None\n",
    "            for c in consumers.get(mm_out, []):\n",
    "                if c.op_type == \"Add\":\n",
    "                    add_node = c; break\n",
    "            Wname = n.input[1] if len(n.input)>1 else None\n",
    "            W = init_map.get(Wname)\n",
    "            out = add_node.output[0] if add_node is not None else mm_out\n",
    "            B = None\n",
    "            if add_node is not None:\n",
    "                a0, a1 = add_node.input[0], add_node.input[1]\n",
    "                cand = a1 if a0 == mm_out else a0\n",
    "                B = resolve_bias_tensor(cand, init_map, const_map, producers)\n",
    "            dense.append({\"kind\":\"MatMulAdd\" if add_node else \"MatMul\",\"index\":idx,\"out\":out,\"W\":W,\"B\":B})\n",
    "            idx += 1\n",
    "    return dense\n",
    "\n",
    "def list_lrelu_nodes(model)->List[Dict]:\n",
    "    outs=[]; idx=0\n",
    "    for n in model.graph.node:\n",
    "        if n.op_type==\"LeakyRelu\":\n",
    "            alpha=0.01\n",
    "            for a in n.attribute:\n",
    "                if a.name==\"alpha\": alpha=a.f; break\n",
    "            outs.append({\"index\":idx,\"out\":n.output[0],\"alpha\":float(alpha)}); idx+=1\n",
    "    return outs\n",
    "\n",
    "def instrument_model_for_outputs(model, names: List[str]):\n",
    "    # Add requested value infos as graph outputs, using shape inference where possible\n",
    "    try:\n",
    "        inferred = shape_inference.infer_shapes(model, strict_mode=True)\n",
    "        inferred_vis = list(inferred.graph.input)+list(inferred.graph.output)+list(inferred.graph.value_info)\n",
    "        vi_map = {vi.name: vi for vi in inferred_vis}\n",
    "    except Exception:\n",
    "        vi_map = {}\n",
    "    g = model.graph\n",
    "    existing_outs = {o.name for o in g.output}\n",
    "    to_add = []\n",
    "    for name in names:\n",
    "        if name in existing_outs: \n",
    "            continue\n",
    "        vi = vi_map.get(name, helper.make_tensor_value_info(name, onnx.TensorProto.FLOAT, None))\n",
    "        to_add.append(vi)\n",
    "    g.output.extend(to_add)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Shape adapter & stage runner ----\n",
    "def adapt_for_model(x: np.ndarray, model_in_shape: Tuple, prefer_3d_last: Optional[int]=None) -> np.ndarray:\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    dims = concrete_dims(model_in_shape)\n",
    "    want_3d = len(dims)==3 and (dims[0] in (1,None)) and (dims[1] in (50,None))\n",
    "    want_2d = len(dims)==2 and (dims[0] in (1,None))\n",
    "    # Prefer exact (1,50,D)\n",
    "    if want_3d and prefer_3d_last is not None:\n",
    "        D = prefer_3d_last\n",
    "        if x.shape == (1,50,D): return x\n",
    "        if x.ndim==2 and x.shape[1]==50*D: return x.reshape(1,50,D)\n",
    "        if x.ndim==3 and x.shape[1]==50 and x.shape[2]*50 == 50*D: return x[:, :, :D]\n",
    "    # Fit declared dims if concrete\n",
    "    if want_3d and dims[2] is not None:\n",
    "        D = dims[2]\n",
    "        if x.shape == (1,50,D): return x\n",
    "        if x.ndim==2 and x.shape[1]==50*D: return x.reshape(1,50,D)\n",
    "    if want_2d and dims[1] is not None:\n",
    "        D = dims[1]\n",
    "        if x.ndim==2 and x.shape[1]==D: return x\n",
    "        if x.ndim==3 and x.shape[1]*x.shape[2]==D: return x.reshape(1,D)\n",
    "    # Fallback: flatten then trim/pad\n",
    "    flat = x.reshape(1,-1)\n",
    "    if want_2d and dims[1] is not None:\n",
    "        D = dims[1]\n",
    "        if flat.shape[1] >= D: return flat[:, :D]\n",
    "        pad = np.zeros((1,D), dtype=np.float32); pad[:, :flat.shape[1]] = flat; return pad\n",
    "    if want_3d and dims[2] is not None:\n",
    "        D = 50*dims[2]\n",
    "        if flat.shape[1] >= D: return flat[:, :D].reshape(1,50,dims[2])\n",
    "        pad = np.zeros((1,D), dtype=np.float32); pad[:, :flat.shape[1]] = flat; return pad.reshape(1,50,dims[2])\n",
    "    return x\n",
    "\n",
    "def run_stage(model_path: Path, x_in: np.ndarray, tag: str, prefer_3d_last: Optional[int]=None) -> np.ndarray:\n",
    "    if not model_path.exists():\n",
    "        raise FileNotFoundError(f\"{tag}: ONNX not found: {model_path}\")\n",
    "    model = onnx.load(str(model_path), load_external_data=True)\n",
    "    dense = list_dense_with_bias_and_outputs(model)\n",
    "    lrs   = list_lrelu_nodes(model)\n",
    "    # Instrument\n",
    "    names = [d[\"out\"] for d in dense] + [r[\"out\"] for r in lrs]\n",
    "    inst = onnx.ModelProto(); inst.CopyFrom(model)\n",
    "    inst = instrument_model_for_outputs(inst, names)\n",
    "    TMP_MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    tmp = TMP_MODEL_DIR / f\"{model_path.stem}__inst.onnx\"\n",
    "    onnx.save(inst, str(tmp))\n",
    "    # Run\n",
    "    sess = ort_session(tmp)\n",
    "    in_vi = sess.get_inputs()[0]\n",
    "    print(f\"[{tag}] provided {x_in.shape} | expects {in_vi.shape}\")\n",
    "    xin = adapt_for_model(x_in, tuple(in_vi.shape), prefer_3d_last=prefer_3d_last)\n",
    "    print(f\"[{tag}] feeding {xin.shape}\")\n",
    "    fetches = names + [sess.get_outputs()[-1].name]\n",
    "    outs = sess.run(fetches, {in_vi.name: xin})\n",
    "    name_to_arr = dict(zip(names, outs[:-1]))\n",
    "    name_to_arr[\"model_output\"] = outs[-1]\n",
    "    # Dumps\n",
    "    out_dir = OUTPUT_ROOT / sanitize(model_path.stem); ensure_dir(out_dir)\n",
    "    dump_txt(out_dir / \"input.txt\", xin, TXT_FLOAT_FMT)\n",
    "    for d in dense:\n",
    "        if d[\"W\"] is not None:\n",
    "            dump_txt(out_dir / f\"dense_{d['index']}_weights.txt\", d[\"W\"], TXT_FLOAT_FMT)\n",
    "        if d[\"B\"] is not None:\n",
    "            dump_txt(out_dir / f\"dense_{d['index']}_bias.txt\", d[\"B\"], TXT_FLOAT_FMT)\n",
    "    for d in dense:\n",
    "        arr = name_to_arr.get(d[\"out\"])\n",
    "        if arr is not None:\n",
    "            dump_txt(out_dir / f\"dense_{d['index']}_output.txt\", arr, TXT_FLOAT_FMT)\n",
    "    for r in lrs:\n",
    "        arr = name_to_arr.get(r[\"out\"])\n",
    "        if arr is not None:\n",
    "            dump_txt(out_dir / f\"leakyrelu_{r['index']}_output.txt\", arr, TXT_FLOAT_FMT)\n",
    "            with open(out_dir / f\"leakyrelu_{r['index']}_alpha.txt\", \"w\") as f:\n",
    "                f.write(f\"{r['alpha']}\\n\")\n",
    "    dump_txt(out_dir / \"model_output.txt\", name_to_arr[\"model_output\"], TXT_FLOAT_FMT)\n",
    "    return name_to_arr[\"model_output\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- ROMDataset and discovery ----\n",
    "def rom_input_b506() -> np.ndarray:\n",
    "    ds = ROMDataset(DATA_ROOT, split=SPLIT, num_particles=50)\n",
    "    dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    event = next(iter(dl))\n",
    "    x = event[FEATURE_KEY].to(DEVICE)\n",
    "    # Normalize to (1,50,6); common arrival: (1,3,50,2)\n",
    "    if x.ndim == 4 and x.shape[0]==1 and x.shape[1:]==(3,50,2):\n",
    "        x = torch.transpose(x,1,2).reshape(1,50,6)\n",
    "    elif x.shape == (1,50,6):\n",
    "        pass\n",
    "    elif x.ndim >= 3 and (x.shape[-1]*x.shape[-2] == 6):\n",
    "        x = x.reshape(1,50,6)\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected ROM shape {tuple(x.shape)}, cannot get (1,50,6)\")\n",
    "    return x.cpu().numpy().astype(np.float32)\n",
    "\n",
    "def discover_solvers() -> List[Path]:\n",
    "    paths = sorted(ONNX_DIR.glob(SOLVER_GLOB), key=lambda p: int(re.search(r\"(\\d+)\", p.stem).group(1)) if re.search(r\"(\\d+)\", p.stem) else 1e9)\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No solver ONNX files found under {ONNX_DIR} with pattern {SOLVER_GLOB}\")\n",
    "    print(\"[DISCOVER] solvers:\", [p.name for p in paths])\n",
    "    return paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Chain runner ----\n",
    "def run_chain():\n",
    "    ensure_dir(OUTPUT_ROOT); ensure_dir(TMP_MODEL_DIR)\n",
    "    if not EMBED_ONNX.exists(): raise FileNotFoundError(f\"embed ONNX not found: {EMBED_ONNX}\")\n",
    "    if not OUTPUT_ONNX.exists(): raise FileNotFoundError(f\"output ONNX not found: {OUTPUT_ONNX}\")\n",
    "    solvers = discover_solvers()\n",
    "    # 1) ROM → (1,50,6)\n",
    "    x = rom_input_b506()\n",
    "    # 2) embed (prefer last=6) → (1,50,768)\n",
    "    x = run_stage(EMBED_ONNX, x, tag=\"EMBED\", prefer_3d_last=6)\n",
    "    # 3) each solver in order — derive preferred last dim from input shape when possible\n",
    "    for i, spath in enumerate(solvers):\n",
    "        sess = ort_session(spath); in_shape = sess.get_inputs()[0].shape\n",
    "        dims = concrete_dims(in_shape)\n",
    "        pref = dims[2] if (len(dims)==3 and isinstance(dims[2], int)) else (dims[1]//50 if len(dims)==2 and isinstance(dims[1], int) and dims[1]%50==0 else None)\n",
    "        print(f\"[SOLVER-{i}] prefers last={pref} from {in_shape}\")\n",
    "        x = run_stage(spath, x, tag=f\"SOLVER-{i}\", prefer_3d_last=pref)\n",
    "    # 4) output (prefer last=128)\n",
    "    x = run_stage(OUTPUT_ONNX, x, tag=\"OUTPUT\", prefer_3d_last=128)\n",
    "    print(\"Chain complete. Dumps are under:\", OUTPUT_ROOT)\n",
    "\n",
    "# Execute\n",
    "run_chain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}