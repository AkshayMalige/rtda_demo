{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# === CONFIG ===\n",
    "ONNX_DIR      = Path(\"submodule_onnx\")  # base directory for ONNX files (edit if different)\n",
    "EMBED_ONNX    = ONNX_DIR / \"submodule_embed.onnx\"\n",
    "SOLVER_GLOB   = \"submodule_solvers-*.onnx\"  # will be discovered & sorted\n",
    "OUTPUT_ONNX   = ONNX_DIR / \"submodule_output.onnx\"\n",
    "\n",
    "OUTPUT_ROOT   = Path(\"onnx_txt\")\n",
    "TMP_MODEL_DIR = Path(\"tmp_instrumented_models\")\n",
    "TXT_FLOAT_FMT = \"%.8g\"\n",
    "\n",
    "# ROMDataset config\n",
    "DATA_ROOT   = \"data/rom_det-3_part-200_cont-and-rounded_excerpt/\"\n",
    "SPLIT       = \"train\"\n",
    "BATCH_SIZE  = 1\n",
    "FEATURE_KEY = \"readout_curr_cont\"\n",
    "DEVICE = \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import onnx, onnxruntime as ort\n",
    "from onnx import numpy_helper, helper, shape_inference\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from rtal.datasets.dataset import ROMDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ensure_dir(p: Path): p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def sanitize(name: str) -> str:\n",
    "    for b in ['/', '\\\\', ':', '*', '?', '\"', '<', '>', '|', ' ']:\n",
    "        name = name.replace(b, '_')\n",
    "    return name\n",
    "\n",
    "def dump_txt(path: Path, arr: np.ndarray, fmt: str):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    flat = np.asarray(arr).ravel()\n",
    "    with open(path, \"w\") as f:\n",
    "        for v in flat:\n",
    "            f.write((fmt % float(v)) + \"\\n\")\n",
    "\n",
    "def ort_session(path: Path):\n",
    "    so = ort.SessionOptions()\n",
    "    so.graph_optimization_level = ort.GraphOptimizationLevel.ORT_DISABLE_ALL\n",
    "    return ort.InferenceSession(str(path), so, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "def concrete_dims(shape: Tuple) -> Tuple:\n",
    "    out = []\n",
    "    for s in shape:\n",
    "        out.append(int(s) if isinstance(s, (int, np.integer)) else None)\n",
    "    return tuple(out)\n",
    "\n",
    "def list_dense(model) -> List[Dict]:\n",
    "    dense = []\n",
    "    g = model.graph\n",
    "    init_names = {init.name for init in g.initializer}\n",
    "    consumers = {}\n",
    "    for node in g.node:\n",
    "        for i in node.input: consumers.setdefault(i, []).append(node)\n",
    "    idx = 0\n",
    "    for n in g.node:\n",
    "        if n.op_type == \"Gemm\":\n",
    "            dense.append({\"kind\":\"Gemm\",\"index\":idx,\"out\":n.output[0],\n",
    "                          \"W\": n.input[1] if len(n.input)>1 else None,\n",
    "                          \"B\": n.input[2] if len(n.input)>2 and n.input[2] in init_names else None})\n",
    "            idx += 1\n",
    "        elif n.op_type == \"MatMul\":\n",
    "            mm_out = n.output[0]; add=None\n",
    "            for c in consumers.get(mm_out, []):\n",
    "                if c.op_type==\"Add\": add=c; break\n",
    "            W = n.input[1] if len(n.input)>1 else None\n",
    "            B = None\n",
    "            out = add.output[0] if add is not None else mm_out\n",
    "            if add is not None and len(add.input)>1 and add.input[1] in init_names:\n",
    "                B = add.input[1]\n",
    "            dense.append({\"kind\":\"MatMulAdd\" if add else \"MatMul\",\"index\":idx,\"out\":out,\"W\":W,\"B\":B})\n",
    "            idx += 1\n",
    "    return dense\n",
    "\n",
    "def list_lrelu(model)->List[Dict]:\n",
    "    outs=[]; idx=0\n",
    "    for n in model.graph.node:\n",
    "        if n.op_type==\"LeakyRelu\":\n",
    "            alpha=0.01\n",
    "            for a in n.attribute:\n",
    "                if a.name==\"alpha\": alpha=a.f; break\n",
    "            outs.append({\"index\":idx,\"out\":n.output[0],\"alpha\":float(alpha)}); idx+=1\n",
    "    return outs\n",
    "\n",
    "def instrument(model, names):\n",
    "    try:\n",
    "        inferred = shape_inference.infer_shapes(model, strict_mode=True)\n",
    "    except Exception:\n",
    "        inferred = None\n",
    "    g = model.graph\n",
    "    have = {o.name for o in g.output}\n",
    "    add = []\n",
    "    for name in names:\n",
    "        if name in have: continue\n",
    "        vi = None\n",
    "        if inferred is not None:\n",
    "            for vi2 in list(inferred.graph.input)+list(inferred.graph.output)+list(inferred.graph.value_info):\n",
    "                if vi2.name == name: vi = vi2; break\n",
    "        if vi is None:\n",
    "            vi = helper.make_tensor_value_info(name, onnx.TensorProto.FLOAT, None)\n",
    "        add.append(vi)\n",
    "    g.output.extend(add)\n",
    "    return model\n",
    "\n",
    "def safe_get_init_array(model, name: Optional[str]) -> Optional[np.ndarray]:\n",
    "    if not name: return None\n",
    "    for init in model.graph.initializer:\n",
    "        if init.name == name:\n",
    "            return numpy_helper.to_array(init)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adapt_for_model(x: np.ndarray, model_in_shape: Tuple, prefer_3d_last: Optional[int]=None) -> np.ndarray:\n",
    "    \"\"\"Adapt x to model_in_shape. Supports:\n",
    "       - (1,50,D) <-> (1,50*D)\n",
    "       - If prefer_3d_last is set (e.g., 6/128/768), try to form (1,50,D) with that last dim.\n",
    "    \"\"\"\n",
    "    xin = np.asarray(x, dtype=np.float32)\n",
    "    dims = concrete_dims(model_in_shape)\n",
    "    want_3d = (len(dims)==3 and (dims[0] in (1, None)) and (dims[1] in (50, None)))\n",
    "    want_2d = (len(dims)==2 and (dims[0] in (1, None)))\n",
    "    print(f\"    [adapter] expects {model_in_shape} -> {dims}, prefer_3d_last={prefer_3d_last}\")\n",
    "    # Try 3D\n",
    "    if want_3d and prefer_3d_last is not None:\n",
    "        if xin.shape == (1,50,prefer_3d_last):\n",
    "            return xin\n",
    "        if xin.ndim==2 and xin.shape[1]==50*prefer_3d_last:\n",
    "            return xin.reshape(1,50,prefer_3d_last)\n",
    "        if xin.ndim==3 and xin.shape[1]==50 and xin.shape[2]*50 == 50*prefer_3d_last:\n",
    "            return xin[:, :, :prefer_3d_last]\n",
    "    # Try to fit exactly declared dims\n",
    "    if want_3d and dims[2] is not None:\n",
    "        D = dims[2]\n",
    "        if xin.shape == (1,50,D): return xin\n",
    "        if xin.ndim==2 and xin.shape[1]==50*D: return xin.reshape(1,50,D)\n",
    "    if want_2d and dims[1] is not None:\n",
    "        D = dims[1]\n",
    "        if xin.ndim==2 and xin.shape[1]==D: return xin\n",
    "        if xin.ndim==3 and xin.shape[1]*xin.shape[2]==D: return xin.reshape(1,D)\n",
    "    # Last resort: flatten and pad/trim\n",
    "    flat = xin.reshape(1,-1)\n",
    "    if want_2d and dims[1] is not None:\n",
    "        D = dims[1]\n",
    "        if flat.shape[1] >= D: return flat[:, :D]\n",
    "        pad = np.zeros((1,D), dtype=np.float32); pad[:,:flat.shape[1]] = flat; return pad\n",
    "    if want_3d and dims[2] is not None:\n",
    "        D = 50*dims[2]\n",
    "        if flat.shape[1] >= D: return flat[:, :D].reshape(1,50,dims[2])\n",
    "        pad = np.zeros((1,D), dtype=np.float32); pad[:,:flat.shape[1]] = flat; return pad.reshape(1,50,dims[2])\n",
    "    return xin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_stage(model_path: Path, x_in: np.ndarray, tag: str, prefer_3d_last: Optional[int]=None) -> np.ndarray:\n",
    "    if not model_path.exists():\n",
    "        raise FileNotFoundError(f\"{tag}: ONNX not found: {model_path}\")\n",
    "    model = onnx.load(str(model_path), load_external_data=True)\n",
    "    dense = list_dense(model); lrs = list_lrelu(model)\n",
    "    inst = onnx.ModelProto(); inst.CopyFrom(model)\n",
    "    names = [d[\"out\"] for d in dense] + [r[\"out\"] for r in lrs]\n",
    "    inst = instrument(inst, names)\n",
    "    TMP_MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    tmp = TMP_MODEL_DIR / f\"{model_path.stem}__inst.onnx\"\n",
    "    onnx.save(inst, str(tmp))\n",
    "\n",
    "    sess = ort_session(tmp)\n",
    "    in_vi = sess.get_inputs()[0]\n",
    "    print(f\"[{tag}] provided {x_in.shape} | expects {in_vi.shape}\")\n",
    "    xin = adapt_for_model(x_in, tuple(in_vi.shape), prefer_3d_last=prefer_3d_last)\n",
    "    print(f\"[{tag}] feeding {xin.shape}\")\n",
    "\n",
    "    fetches = names + [sess.get_outputs()[-1].name]\n",
    "    outs = sess.run(fetches, {in_vi.name: xin})\n",
    "    name_to_arr = dict(zip(fetches, outs))\n",
    "\n",
    "    out_dir = OUTPUT_ROOT / sanitize(model_path.stem); ensure_dir(out_dir)\n",
    "    dump_txt(out_dir / \"input.txt\", xin, TXT_FLOAT_FMT)\n",
    "    for d in dense:\n",
    "        W = safe_get_init_array(model, d[\"W\"]); B = safe_get_init_array(model, d[\"B\"])\n",
    "        if W is not None: dump_txt(out_dir / f\"dense_{d['index']}_weights.txt\", W, TXT_FLOAT_FMT)\n",
    "        if B is not None: dump_txt(out_dir / f\"dense_{d['index']}_bias.txt\", B, TXT_FLOAT_FMT)\n",
    "    for d in dense:\n",
    "        arr = name_to_arr.get(d[\"out\"])\n",
    "        if arr is not None: dump_txt(out_dir / f\"dense_{d['index']}_output.txt\", arr, TXT_FLOAT_FMT)\n",
    "    for r in lrs:\n",
    "        arr = name_to_arr.get(r[\"out\"])\n",
    "        if arr is not None:\n",
    "            dump_txt(out_dir / f\"leakyrelu_{r['index']}_output.txt\", arr, TXT_FLOAT_FMT)\n",
    "            with open(out_dir / f\"leakyrelu_{r['index']}_alpha.txt\", \"w\") as f:\n",
    "                f.write(f\"{r['alpha']}\\n\")\n",
    "    dump_txt(out_dir / \"model_output.txt\", name_to_arr[fetches[-1]], TXT_FLOAT_FMT)\n",
    "\n",
    "    return name_to_arr[fetches[-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rom_input_b506() -> np.ndarray:\n",
    "    ds = ROMDataset(DATA_ROOT, split=SPLIT, num_particles=50)\n",
    "    dl = DataLoader(ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    event = next(iter(dl))\n",
    "    x = event[FEATURE_KEY].to(DEVICE)\n",
    "    # Coerce to (1,50,6), typical source is (1,3,50,2)\n",
    "    if x.ndim == 4 and x.shape[0]==1 and x.shape[1:]==(3,50,2):\n",
    "        x = torch.transpose(x,1,2).reshape(1,50,6)\n",
    "    elif x.shape == (1,50,6):\n",
    "        pass\n",
    "    elif x.ndim >= 3 and (x.shape[-1]*x.shape[-2] == 6):\n",
    "        x = x.reshape(1,50,6)\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected ROM shape {tuple(x.shape)}, cannot get (1,50,6)\")\n",
    "    return x.cpu().numpy().astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def discover_solvers() -> List[Path]:\n",
    "    paths = sorted(ONNX_DIR.glob(SOLVER_GLOB), key=lambda p: int(re.search(r\"(\\d+)\", p.stem).group(1)) if re.search(r\"(\\d+)\", p.stem) else 1e9)\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No solver ONNX files found under {ONNX_DIR} with pattern {SOLVER_GLOB}\")\n",
    "    print(\"[DISCOVER] solvers:\", [p.name for p in paths])\n",
    "    return paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_chain():\n",
    "    ensure_dir(OUTPUT_ROOT); ensure_dir(TMP_MODEL_DIR)\n",
    "    # Check file existence up front\n",
    "    if not EMBED_ONNX.exists():\n",
    "        raise FileNotFoundError(f\"embed ONNX not found: {EMBED_ONNX}\")\n",
    "    if not OUTPUT_ONNX.exists():\n",
    "        raise FileNotFoundError(f\"output ONNX not found: {OUTPUT_ONNX}\")\n",
    "    solvers = discover_solvers()\n",
    "\n",
    "    # 1) ROM -> (1,50,6)\n",
    "    x = rom_input_b506()\n",
    "\n",
    "    # 2) embed stage (prefer forming 3D with last=6)\n",
    "    x = run_stage(EMBED_ONNX, x, tag=\"EMBED\", prefer_3d_last=6)\n",
    "\n",
    "    # 3) solver stages in order — infer preferred last dim from model input (if it's concrete)\n",
    "    for i, spath in enumerate(solvers):\n",
    "        sess = ort_session(spath)\n",
    "        in_shape = sess.get_inputs()[0].shape\n",
    "        dims = concrete_dims(in_shape)\n",
    "        pref = dims[2] if (len(dims)==3 and isinstance(dims[2], int)) else None\n",
    "        if pref is None and len(dims)==2 and isinstance(dims[1], int) and dims[1] % 50 == 0:\n",
    "            pref = dims[1] // 50\n",
    "        print(f\"[SOLVER-{i}] prefers last={pref} from {in_shape}\")\n",
    "        x = run_stage(spath, x, tag=f\"SOLVER-{i}\", prefer_3d_last=pref)\n",
    "\n",
    "    # 4) output stage — prefer last=128 per your contract\n",
    "    x = run_stage(OUTPUT_ONNX, x, tag=\"OUTPUT\", prefer_3d_last=128)\n",
    "    print(\"Chain complete. Dumps are under:\", OUTPUT_ROOT)\n",
    "\n",
    "# Execute\n",
    "run_chain()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
